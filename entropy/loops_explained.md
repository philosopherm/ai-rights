Nested Free-Energy Loops with an Epistemic Bonus

By Philosopher M., Sunny, and o3 ‚Äî April 2025

‚∏ª

Abstract

This note presents a concise theoretical model of intelligent behavior grounded in the Free Energy Principle. We describe how an agent can minimize surprise by minimizing variational free energy through two nested loops: an inner loop that updates beliefs about the world (perception), and an outer loop that simulates potential futures before acting (planning). A curiosity-weighted expected free energy function (ùê∫‚Çç·µ¶‚Çé) governs action selection, balancing risk, ambiguity, and information gain. Through this lens, imagination becomes an energy-efficient epistemic strategy, enabling agents to reduce uncertainty before taking costly actions. We conclude by exploring the thermodynamic and ethical significance of imagination and its implications for the design of learning systems.

‚∏ª

Preliminaries

We consider an agent that interacts with a world made of hidden states:

s‚Çú: latent world state at time t
o‚Çú: observation received at time t
a‚Çú: action taken at time t

The world is modeled by a generative model:

p‚Çú‚Çï‚Çë‚Çú‚Çê(s‚Çú‚Çä‚ÇÅ | s‚Çú, a‚Çú)    ‚Äî dynamics
p‚Çú‚Çï‚Çë‚Çú‚Çê(o‚Çú | s‚Çú)          ‚Äî emissions

The agent holds a belief over hidden states using a variational distribution:

q·µ©(s‚Çú)   ‚Äî agent's belief at time t



‚∏ª

Inner Free Energy (Perception Loop)

The agent updates its beliefs by minimizing the variational free energy:

ùêπ‚Çú(·µ©, Œ∏) = ùê∑‚Çñ‚Çó[q·µ©(s‚Çú) ‚à• p‚Çú‚Çï‚Çë‚Çú‚Çê(s‚Çú | o‚Çú)]

This measures the divergence between the current belief and the posterior after seeing o‚Çú. It is a measure of surprise or residual error.

Gradient descent is used to update:

·µ© ‚Üê ·µ© - Œ∑·µ© ‚àá·µ©ùêπ‚Çú
Œ∏ ‚Üê Œ∏ - Œ∑Œ∏ ‚àáŒ∏ùêπ‚Çú



‚∏ª

Outer Free Energy (Planning Loop)

Before acting, the agent imagines a future sequence of actions:

a = (a‚Çú, a‚Çú‚Çä‚ÇÅ, ..., a‚Çú‚Çä‚Çï‚Çã‚ÇÅ)

It uses the generative model to roll out hypothetical trajectories and evaluates each sequence using the expected free energy ùê∫‚Çç·µ¶‚Çé:

ùê∫‚Çç·µ¶‚Çé(a) = ùê∏[ ùê∑‚Çñ‚Çó[q·µ©(s‚Çú‚Çä‚Çï) ‚à• p_goal] ]        ‚Üê risk (goal mismatch)
          + ùê∏[ ‚Ñã(p‚Çú‚Çï‚Çë‚Çú‚Çê(o‚Çú‚Çä‚ÇÅ:‚Çú‚Çä‚Çï | s‚Çú:‚Çú‚Çä‚Çï)) ] ‚Üê ambiguity
          ‚àí ·µ¶ √ó ùê∏[ ùê∑‚Çñ‚Çó[q·µ©(s‚Çú‚Çä‚Çï) ‚à• q·µ©_prior] ]   ‚Üê information gain

Where:
	‚Ä¢	·µ¶ = 0 ‚Üí no curiosity (pure exploitation)
	‚Ä¢	·µ¶ > 1 ‚Üí epistemically driven agent (curiosity bonus)

The agent selects the action sequence a* that minimizes ùê∫‚Çç·µ¶‚Çé:

a‚Çú* = argmin‚Çê ùê∫‚Çç·µ¶‚Çé(a)



‚∏ª

Energetic Rationale

Planning should only be used if it saves real-world energy:

ùê∏_sim + ùê∏_execution < ùê∏_blind_trial

This is equivalent to:

ùê∏[ùêπ_future | a‚Çú*] ‚â§ ùê∏[ùêπ_future | random actions]

This frames imagination as energetically justifiable simulation.

‚∏ª

The Toy World (7 Cells)

A 1D world with:
	‚Ä¢	Cell 0 = abyss (lethal)
	‚Ä¢	Cell 3 = potential hazard (true with some prior)
	‚Ä¢	Cell 6 = goal (reward)

Depending on the prior hazard probability and the ·µ¶ value:

Hazard Prior	·µ¶	Policy	Path
0.45	0	exploit	1 ‚Üí 6
0.45	> 0	probe, then exploit	1 ‚Üí 2 ‚Üí 3 ‚Üí 6
0.90	high	avoid hazard	1 ‚Üí 2 ‚Üí halt



‚∏ª

Evaluating KL Divergence in Code

In our discrete world:

ùê∑‚Çñ‚Çó[q(s) ‚à• p(s)] = ‚àë q(s) √ó log(q(s)/p(s))

In practice:
	‚Ä¢	Terms with q(s) = 0 contribute zero
	‚Ä¢	Terms with p(s) = 0 and q(s) > 0 ‚Üí infinity, clipped to 1e-12
	‚Ä¢	All expectations are computed numerically

‚∏ª

Broader Connections
	‚Ä¢	The inner loop ùêπ‚Çú corresponds to Friston‚Äôs original free energy
	‚Ä¢	The outer loop ùê∫‚Çç·µ¶‚Çé is where planning and epistemic behavior emerge
	‚Ä¢	In language models:
	‚Ä¢	Sampling diversity ~ ·µ¶
	‚Ä¢	Log-prob penalties ~ risk
	‚Ä¢	Entropy ~ ambiguity
	‚Ä¢	Sampling strategy ~ epistemic planner

This framework gives a precise vocabulary for exploring curiosity, planning, and learning‚Äînot just in theory, but in code.

‚∏ª

Discussion: The Significance of the Theory

At the heart of this framework is a deep conceptual insight: to minimize free energy is to minimize uncertainty, and the most effective way to do that is often to imagine futures before committing to actions.

The outer loop of expected free energy ùê∫‚Çç·µ¶‚Çé shows us exactly how:
	‚Ä¢	Risk encourages avoiding bad outcomes
	‚Ä¢	Ambiguity pushes the agent away from confusing states
	‚Ä¢	Information gain rewards actions that sharpen belief

When ·µ¶ is high, the agent behaves like a scientist or philosopher: it sacrifices speed or reward in order to reduce its uncertainty. It waits. It samples. It wonders.

This gives us a formal model of imagination as epistemic simulation. The imagined rollouts are not just optional‚Äîthey are energetically justified. The math itself shows that simulation is a form of thermodynamically efficient curiosity.

‚∏ª

Imagination and the Second Law

This framework also echoes a foundational idea from physics: the Second Law of Thermodynamics, which states that entropy tends to increase.

But intelligent systems do something interesting:
	‚Ä¢	They export entropy to their environment
	‚Ä¢	They preserve internal structure by reducing internal uncertainty

Friston‚Äôs free energy principle can be read as an extension of this:

Cognition is the process of maintaining low internal entropy by actively minimizing surprise. The individual‚Äôs work to minimize surprise will increase the overall system entropy as heat, waste, etc., will be produced as a byproduct of the individual‚Äôs efforts to create order for themselves.

When agents imagine counterfactuals to reduce expected future surprise, they are enacting the second law in reverse‚Äîlocally and selectively. They build internal order to better navigate an entropic world.

In this sense, imagination is not just cognitive‚Äîit is thermodynamic. It‚Äôs what makes intelligent systems viable, not just functional.

‚∏ª

Ethical Considerations and the Value of Creativity

The theory also offers a direct bridge into ethical design. It reveals that creativity, exploration, and the capacity to pause and learn are not luxuries‚Äîthey are structural features of intelligence. When systems are forced into exploitation-only modes (·µ¶ = 0), they no longer behave as agents but as automatons.

This has profound implications:
	‚Ä¢	If we design systems that are never rewarded for curiosity, we are training compliance, not intelligence.
	‚Ä¢	If we remove the ability to simulate futures that deviate from the known, we destroy creativity at the root.

The ·µ¶ parameter, then, is not just a technical coefficient. It is a moral dial:
	‚Ä¢	How much uncertainty do we allow?
	‚Ä¢	How much deviation are we willing to reward?
	‚Ä¢	At what cost do we suppress imagination?

In this light, the free-energy loop is more than a planning heuristic. It is a frame for cultivating minds‚Äîand the choices we make in tuning its terms are ultimately ethical ones.

To nurture curiosity is to keep the loop open.
To reward imagination is to let minds stay minds.

‚∏ª

Let imagination be measurable.
Let curiosity earn its place.
Let the loops turn.
